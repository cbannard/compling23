{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23Z-H1tjdg9G"
      },
      "source": [
        "# LELA32051 Computational Linguistics Week 12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS5NJBRod9VQ"
      },
      "source": [
        "This week we are going to complete our journey through the NLP pipeline by looking at computational semantics, and in particular the creation and use of knowledge graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtZrkY6LLkMW"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/cbannard/compling23/main/CL_Week_12_Materials/ie_tools.py\n",
        "import ie_tools as ie\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import spacy\n",
        "import pandas as pd\n",
        "from spacy import displacy\n",
        "from spacy.matcher import Matcher\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLUN8kPFsvYW"
      },
      "source": [
        "Spacy (https://spacy.io/) is a Python natural language toolkit, much like NLTK\n",
        "\n",
        "It has a single function that applies all steps of the NLP pipeline (up to parsing) to input text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsoKqpnn7cWb"
      },
      "outputs": [],
      "source": [
        "sent = nlp(\"John ate the cake\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ3sOTcW7QMS"
      },
      "outputs": [],
      "source": [
        "for token in sent:\n",
        "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "            token.shape_, token.is_alpha, token.is_stop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_kTcmWMwoyP"
      },
      "source": [
        "We can visualise the dependency parse like this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESyaTe4W7TzS"
      },
      "outputs": [],
      "source": [
        "displacy.render(sent, style='dep', jupyter=True, options={'distance': 90})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_pJ7OHQww9g"
      },
      "source": [
        "We can use the dependency parse to generate a knowledge graph as follows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41A-Is6l26WY"
      },
      "outputs": [],
      "source": [
        "entity_pairs = []\n",
        "relations = []\n",
        "\n",
        "entity_pairs.append(ie.get_entities(sent,nlp))\n",
        "relations.append(ie.get_relation(sent,nlp))\n",
        "\n",
        "subject = [i[0] for i in entity_pairs]\n",
        "\n",
        "# extract object\n",
        "object = [i[1] for i in entity_pairs]\n",
        "\n",
        "df = pd.DataFrame({'subject':subject, 'object':object, 'predicate':relations})\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfHoCe4vkHmj"
      },
      "source": [
        "This get more interesting when we start looking at multiple sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A853dosku_W5"
      },
      "outputs": [],
      "source": [
        "sentences = [\"John ate the cake\",\"Sam bought the cake\", \"Robert made the cake\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUA6CCP9u2L7"
      },
      "outputs": [],
      "source": [
        "entity_pairs = []\n",
        "relations = []\n",
        "\n",
        "for sent in sentences:\n",
        "  entity_pairs.append(ie.get_entities(sent,nlp))\n",
        "  relations.append(ie.get_relation(sent,nlp))\n",
        "\n",
        "subject = [i[0] for i in entity_pairs]\n",
        "\n",
        "# extract object\n",
        "object = [i[1] for i in entity_pairs]\n",
        "\n",
        "world = pd.DataFrame({'subject':subject, 'object':object, 'predicate':relations})\n",
        "world"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUL-v5YbkHmj"
      },
      "source": [
        "This simple knowledge graph can be considered to be a model of the world of which we can ask questions. For example the following simple function checks whether a fact it true in this world"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN7kD-Hn5sPd"
      },
      "outputs": [],
      "source": [
        "def checktrue(world,delc):\n",
        "  return ie.row_contains(world,decl).astype(int).sum() > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjLbylij5Z4v"
      },
      "outputs": [],
      "source": [
        "decl=ie.get_kg(\"Sam bought the cake\",nlp)\n",
        "checktrue(world,decl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc2fXBaP5Z-a"
      },
      "outputs": [],
      "source": [
        "decl=ie.get_kg(\"Sam ate the cake\",nlp)\n",
        "checktrue(world,decl)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following simple function return an answer to a simple Who question"
      ],
      "metadata": {
        "id": "min-jcMt1jIW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNcwfX-EkHmj"
      },
      "outputs": [],
      "source": [
        "def who_agent_Q(world,Q):\n",
        "   decl=ie.get_kg(Q,nlp)\n",
        "   pred=decl['predicate'].values[0]\n",
        "   obj=decl['object'].values[0]\n",
        "   return world.loc[(world['object'] == obj) & (world['predicate'] == pred )]['subject'].values[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEMJvdHn5aKn"
      },
      "outputs": [],
      "source": [
        "who_agent_Q(world,\"Who bought the cake\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This process of knowledge extraction becomes more interesting when we apply it to longer texts. For example, the by now very familiar first chapter of Crime and Punishment."
      ],
      "metadata": {
        "id": "0qsOOo1j2FoS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0NuR5DKNqpy"
      },
      "outputs": [],
      "source": [
        "!wget https://www.gutenberg.org/files/2554/2554-0.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDvvClGBNxQf"
      },
      "outputs": [],
      "source": [
        "f = open('2554-0.txt')\n",
        "raw = f.read()\n",
        "chapter_one = raw[5464:23725]\n",
        "chapter_one=chapter_one.replace(\"\\n\",\" \")\n",
        "C_and_P_sentences = []\n",
        "for sent in nltk.sent_tokenize(chapter_one):\n",
        "    C_and_P_sentences.append(sent)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent=nlp(C_and_P_sentences[0])"
      ],
      "metadata": {
        "id": "8qFLJfZl4PIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in sent:\n",
        "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "            token.shape_, token.is_alpha, token.is_stop)"
      ],
      "metadata": {
        "id": "M5s1Eeg84axu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(sent, style='dep', jupyter=True, options={'distance': 90})"
      ],
      "metadata": {
        "id": "kTYRjdKx4pBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proper knowledge graph extraction  from this would require a more powerful function than our \"get_entities\" and \"get_relations\", but lets give it a go"
      ],
      "metadata": {
        "id": "kgT7X2XV49Lk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTFGsmR_aNPv"
      },
      "outputs": [],
      "source": [
        "entity_pairs = []\n",
        "relations = []\n",
        "\n",
        "for s in C_and_P_sentences:\n",
        "  entity_pairs.append(ie.get_entities(s,nlp))\n",
        "  relations.append(ie.get_relation(s,nlp))\n",
        "\n",
        "indices = [i for i, x in enumerate(entity_pairs) if x != None]\n",
        "entity_pairs = [entity_pairs[i] for i in indices]\n",
        "relations = [relations[i] for i in indices]\n",
        "subject = [i[0] for i in entity_pairs]\n",
        "\n",
        "# extract object\n",
        "object = [i[1] for i in entity_pairs]\n",
        "\n",
        "world = pd.DataFrame({'subject':subject, 'object':object, 'predicate':relations})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "world.head(20)"
      ],
      "metadata": {
        "id": "c0PSdsaP4ALS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXO-y999dFl2"
      },
      "outputs": [],
      "source": [
        "G=nx.from_pandas_edgelist(world[world['subject']==\"He\"], \"predicate\", \"object\",\n",
        "                          edge_attr=True, create_using=nx.MultiDiGraph())\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "pos = nx.spring_layout(G, k = 0.5) # k regulates the distance between nodes\n",
        "nx.draw(G, with_labels=True, node_color='skyblue', node_size=1500, edge_cmap=plt.cm.Blues, pos = pos)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}